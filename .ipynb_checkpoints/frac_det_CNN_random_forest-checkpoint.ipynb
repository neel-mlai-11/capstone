{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12059f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd8f14f",
   "metadata": {},
   "source": [
    "# \n",
    "tensorflow and keras: For building and training the CNN.\n",
    "ImageDataGenerator: For image preprocessing and augmentation.\n",
    "VGG16: Pre-trained CNN model for feature extraction.\n",
    "RandomForestClassifier: For classification using extracted features.\n",
    "accuracy_score: For evaluating the classifier.\n",
    "numpy, os, and train_test_split: General utilities for data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06100009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Data Generators:\n",
    "\n",
    "\n",
    "# Directories for training and testing data\n",
    "#train_dir = 'C:\\\\Users\\\\nsona\\\\Downloads\\\\archive (2)\\\\BoneFractureDataset\\\\training'\n",
    "#test_dir = 'C:\\\\Users\\\\nsona\\\\Downloads\\\\archive (2)\\\\BoneFractureDataset\\\\testing'\n",
    "\n",
    "train_dir = 'BoneFractureDataset\\\\training'\n",
    "test_dir = 'BoneFractureDataset\\\\testing'\n",
    "\n",
    "\n",
    "# Data generators with data augmentation for training and rescaling for testing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Creating the training and testing data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de76ce",
   "metadata": {},
   "source": [
    "train_dir and test_dir: Directories containing training and testing images.\n",
    "ImageDataGenerator: Augments and resizes images for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f6bbf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nsona\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nsona\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Build a CNN model for feature extraction\n",
    "input_tensor = Input(shape=(150, 150, 3))\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "# Add a flatten layer to convert 3D outputs to 2D\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "#Extract Features and Labels from the Dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98bbae",
   "metadata": {},
   "source": [
    "VGG16: Pre-trained CNN model, excluding the top layers.\n",
    "Flatten: Converts 3D features to 2D for the Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aa1055f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277/277 [==============================] - 1397s 5s/step\n",
      "19/19 [==============================] - 95s 5s/step\n"
     ]
    }
   ],
   "source": [
    "def extract_features(generator, model):\n",
    "    features = model.predict(generator)\n",
    "    labels = generator.classes\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, feature_extractor)\n",
    "test_features, test_labels = extract_features(test_generator, feature_extractor)\n",
    "\n",
    "#extract_features: Function to extract features using the CNN and retrieve labels from the generator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ca12a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RandomForestClassifier: Trains a Random Forest on the extracted features.\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9819befc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Classifier:\n",
    "test_predictions = rf_classifier.predict(test_features)\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fccaf883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "The image is predicted to be not fractured.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "The image is predicted to be not fractured.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "The image is predicted to be fractured.\n",
      "1/1 [==============================] - 1s 946ms/step\n",
      "The image is predicted to be fractured.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "The image is predicted to be fractured.\n",
      "1/1 [==============================] - 1s 743ms/step\n",
      "The image is predicted to be not fractured.\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "The image is predicted to be not fractured.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(img_path, target_size=(150, 150)):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  # Rescale to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "def predict_single_image(img_path):\n",
    "    img_array = preprocess_image(img_path)\n",
    "    features = feature_extractor.predict(img_array)\n",
    "    prediction = rf_classifier.predict(features)\n",
    "    return prediction[0]\n",
    "\n",
    "# Example usage\n",
    "img_path =    'C:\\\\Users\\\\nsona\\\\Downloads\\\\archive (2)\\\\BoneFractureDataset\\\\testing\\\\fractured\\\\1.jpg'\n",
    "prediction = predict_single_image(img_path)\n",
    "if prediction == 1:\n",
    "    print(\"The image is predicted to be fractured.\")\n",
    "else:\n",
    "    print(\"The image is predicted to be not fractured.\")\n",
    "    \n",
    "img_path =    'C:\\\\Users\\\\nsona\\\\Downloads\\\\archive (2)\\\\BoneFractureDataset\\\\testing\\\\fractured\\\\1-rotated1.jpg'\n",
    "prediction = predict_single_image(img_path)\n",
    "if prediction == 1:\n",
    "    print(\"The image is predicted to be fractured.\")\n",
    "else:\n",
    "    print(\"The image is predicted to be not fractured.\")\n",
    "    \n",
    "img_path =    'C:\\\\Users\\\\nsona\\\\Downloads\\\\archive (2)\\\\BoneFractureDataset\\\\testing\\\\fractured\\\\1-rotated1-rotated1.jpg'\n",
    "prediction = predict_single_image(img_path)\n",
    "if prediction == 1:\n",
    "    print(\"The image is predicted to be fractured.\")\n",
    "else:\n",
    "    print(\"The image is predicted to be not fractured.\")\n",
    "    \n",
    "img_path =    'C:\\\\Users\\\\nsona\\\\Downloads\\\\archive (2)\\\\BoneFractureDataset\\\\testing\\\\fractured\\\\1-rotated1-rotated1-rotated1.jpg'\n",
    "prediction = predict_single_image(img_path)\n",
    "if prediction == 1:\n",
    "    print(\"The image is predicted to be fractured.\")\n",
    "else:\n",
    "    print(\"The image is predicted to be not fractured.\")\n",
    "    \n",
    "img_path =    'C:\\\\Users\\\\nsona\\\\Downloads\\\\archive (2)\\\\BoneFractureDataset\\\\testing\\\\fractured\\\\1-rotated1-rotated1-rotated2.jpg'\n",
    "prediction = predict_single_image(img_path)\n",
    "if prediction == 1:\n",
    "    print(\"The image is predicted to be fractured.\")\n",
    "else:\n",
    "    print(\"The image is predicted to be not fractured.\")\n",
    "    \n",
    "img_path =    'C:\\\\Users\\\\nsona\\\\Downloads\\\\archive (2)\\\\BoneFractureDataset\\\\testing\\\\fractured\\\\1-rotated1-rotated1-rotated3.jpg'\n",
    "prediction = predict_single_image(img_path)\n",
    "if prediction == 1:\n",
    "    print(\"The image is predicted to be fractured.\")\n",
    "else:\n",
    "    print(\"The image is predicted to be not fractured.\")\n",
    "    \n",
    "img_path =    'C:\\\\Users\\\\nsona\\\\Downloads\\\\archive (2)\\\\BoneFractureDataset\\\\testing\\\\fractured\\\\2.jpg'\n",
    "\n",
    "prediction = predict_single_image(img_path)\n",
    "if prediction == 1:\n",
    "    print(\"The image is predicted to be fractured.\")\n",
    "else:\n",
    "    print(\"The image is predicted to be not fractured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203dba74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
